\section{Abwägung}
In diesem Kapitel sollen ein paar grundsätzliche Fragen in bezug auf Chatbots und Ethik diskutiert werden. 
Als Grundlage dient uns das Dokument \glqq Entscheidungsunterstützung mit Künstlicher Intelligenz\grqq\footnote{vgl. \cite{Bitkom}}, verfasst von Bitcom und dem Deutsches Forschungszentrum für Künstliche Intelligenz GmbH. 
Speziell Kapital 8 \glqq Automatisierte Entscheidungen aus ethischer Sicht\grqq\ wird für unsere Abwägung herangezogen. 
Wir begeben uns nun in die Sicht eines Anwenders, der mit einem Chatbot kommuniziert. 

Wie wir es bereits heute erleben, werden immer mehr Systeme \glqq intelligent\grqq. 
Sei es ein Chatbot, der mit einer \ac{ki} arbeitet oder ein autonom fahrendes Auto. 
Hinter diesen Prozessen steckt der Gedanke der Prozessoptimierung und der effizienteren Gestaltung von Prozessen. 
Doch wir dürfen an dieser Stelle die Ethik nicht vergessen. 
Was für den einen Menschen von Vorteil sein mag, das stellt sich für andere Menschen womöglich als Nachteil heraus.

\textbf{Chanchengleichheit} ist hier der Punkt. Wie kann sichergestellt werden, dass durch die \ac{ki} im Hintergrund keine Diskriminierung stattfindet. Sei es aufgrund des Geschlechts, der ethnischen Herkunft, der Religion oder der sexuellen Überzeugung. Auch heute noch ist die Homosexualität ein Tabuthema in weiten Teilen der Gesellschaft. 
Der Rechtsstaat hat zwar die Ehe zwischen homosexuellen Paaren erlaubt, allerdings bedeutet dies nicht, dass Homosexuelle dadurch automatisch in der Gesellschaft anerkannt werden. 
Es gibt nach wie vor viele Vorurteile gegenüber dieser sexuellen Orientierung. 
Bei der Auswahl für eine freie Arbeitsstelle könnte beispielsweise ein homosexueller gegenüber heterosexuellen Bewerbern im Nachteil sein.

Was ist, wenn dem Chatbot die sexuelle Orientierung bekannt ist und er aus diversen Quellen gelernt hat, dass Homosexualität nicht gut ist? 
Dies führt zu der oben genannten Chancenungleichheit. 
%Wahrscheinlich ist es dem Anwender nicht einmal bewusst, dass der Chatbot eine Art Vorurteil gegenüber dem Anwender hat.

\textbf{Informationsfreiheit und freie Meinungsbildung} ist der nächste Punkt. Dies umfasst zunächst mal den Zugang zu Informationen.
Wie kann der Zugriff auf Informationen gewährleistet werden? Was ist wenn Chatbots Falschmeldungen verteilen? Wie können die Bürger davor geschützt werden?

Auch Prof. Dr. Oliver Bendel\footnote{Er ist Ethiker und Wirtschaftsinformatiker an der Fachhochschule Nordwestschweiz.} sieht hier eine große Gefahr. 
Es gibt bereits Newsportale, die absichtlich Lügen verbreiten -- Stichwort \enquote{Fakenews}. 
Diese tragen dann indirekt zur Meinungsbildung bei. 
Die Erstellung der Falschmeldungen geschieht zum Teil durch Menschen als auch durch Maschinen. 

Zu Demonstrationszwecken entwickelte er den Lügenbot. Dieser Chatbot ist konzipiert dazu Lügen zu verbreiten. 
Das Ziel dieses Projekts ist es, die Strategien des maschinellen Lügens aufzuzeigen und zu verstehen. 
Dies soll dabei helfen, Programmierern sowie Anwendern mögliche Gefahren, die durch diese Technik entstehen kann aufzuzeigen.\footnote{vgl. \cite{Bendel}} 

PLATON

Wie bereits Aristoteles erkannte hat jedes Problem seine eigene Genauigkeit. Speziell Chatbots und die \ac{ki} bedürfen einer sehr hohen Genauigkeit. Wir müssen uns im klaren sein, welche Auswirkungen unsere technologischen Fortschritte auf uns Menschen haben. Verschwindet vielleicht die menschliche Komponente durch den Einsatz eines Chatbots? 
Es gibt unzählige Fragen, die genau betrachtet und bewertet werden müssen. 
Das menschliche Bestreben nach Wissen kann ein Chatbot möglicherweise abdecken, jedoch muss weiterhin sichergestellt werden, dass die zur Verfügung gestellten Informationen auch richtig sowie frei von Vorurteilen sind.

NIETZSCHE




