\section{Abwägung}
In diesem Kapitel sollen ein paar grundsätzliche Fragen in bezug auf Chatbots und Ethik diskutiert werden. Als Grundlage dient uns das Dokument \glqq Entscheidungsunterstützung mit Künstlicher Intelligenz\grqq\footnote{vgl. \cite{Bitkom}} verfasst von Bitcom und dem Deutsches Forschungszentrum für Künstliche Intelligenz GmbH. Speziell Kapital 8 \glqq Automatisierte Entscheidungen aus ethischer Sicht\grqq\ wird für unsere Abwägung herangezogen. Wir begeben uns nun in die Sicht eines Anwenders der mit einem Chatbot kommuniziert. 

Wie wir es bereits heute erleben, werden immer mehr Systeme \glqq intelligent\grqq. Sei es ein Chatbot, der mit einer \ac{ki} arbeitet oder ein autonom fahrendes Auto. Hinter diesen Prozessen steckt der Gedanke der Prozessoptimierung und der effizienteren Gestaltung der Prozesse. Doch wir dürfen an dieser Stelle die Ethik nicht vergessen. Was für den einen Menschen einen Vorteil bedeutet, ist vielleicht für einen anderen Menschen ein Nachteil. \newline
\textbf{Chanchengleichheit} ist hier der Punkt. Wie kann sichergestellt werden, dass durch die \ac{ki} im Hintergrund keine Diskrimierung stattfindet. Sei es aufgrund des Geschlechts, der ethischen Herkunft, der Religion oder der sexuellen Überzeugung. Auch heute noch ist die Homosexualität ein Tabuthema in der Gesellschaft. Der Rechtsstaat hat zwar die Ehe zwischen homosexuellen Paaren erlaubt, allerdings bedeuetet dies nicht, dass Homosexuele in der Gesellschaft anerkannt sind. Es gibt noch viele Vorurteile gegenüber dieser sexuellen Überzeugung. Wir sind der Meinung, dass zum Beispiel bei einer Jobsuche ein heterosexueller einem homosexuellen bevorzugt wird. Was ist wenn dem Chatbot die sexuelle Orientierung bekannt ist und er aus diversen Quellen gelernt hat, dass Homsexualität nicht gut ist? Dies führt zu der oben genannten Chancenungleichheit. Wahrscheinlich ist es dem Anwender nicht einmal bewusst, dass der Chatbot eine Art Vorurteil gegenüber dem Anwender hat. \newline
\textbf{Informationsfreiheit und freie Meinungsbildung} ist der nächste Punkt. Dies umfasst zunächst mal den Zugang zu informationen. Wie kann der Zugriff auf Informationen gewährleistet werden? Was ist wenn Chatbots Falschmeldungen verteilen? Wie können die Bürger davor geschützt werden? \newline
Auch Prof. Dr. Oliver Bendel\footnote{Er ist Ethiker und Wirtschaftsinformatiker an der Fachhochschule Nordwestschweiz.} sieht hier eine große Gefahr. Es gibt bereits Newsportale, die absichtlich Lügen verbreiten. Diese tragen dann indirekt zur Meinungsbildung bei. Die Erstellung der Falschmeldungen geschieht zum Teil durch Menschen als auch durch Maschinen. Zu Demostrationszwecken entwickelte er den Lügenbot. Dieser Chatbot ist konzipiert um Lügen zu verbreiten. Das Ziel ist es, die Strategien des maschinellen Lügens aufzuzeigen und zu verstehen. Dies soll den Programmieren und Anwendern helfen die Gefahren zu erkennen.\footnote{vgl. \cite{Bendel}} 

PLATON

Wie bereits Aristoteles erkannte hat jedes Problem seine eigene Genauigkeit. Speziell Chatbots und die \ac{ki} bedürfen einer sehr hohen Genauigkeit. Wir müssen uns im klaren sein, welche Auswirkungen unsere technologischen Fortschritte auf uns Menschen haben. Verschwindet vielleicht das menschliche Komponente durch den Einsatz eines Chatbots? Es gibt unzählige Fragen die genau betrachtet und bewertet werden müssen. Das Bestreben nach Wissen kann ein Chatbot zwar abdecken. Aber bringen uns die Informationen eines Chatbots etwas wenn diese falsch oder durch Vorurteile verändert wurden.  

NIETZSCHE




